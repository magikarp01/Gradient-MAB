For results, give the runs the same starting points

Figure out if higher dimensions are slower
(steps are slower but more runs are done per step)
alternatively, do work to figure out how expensive functions need to be to outweigh the cost of OCBAFit

Implement metaMax-infinity

for fitAlloc, only remember the past p points for regression
(accounting for every point in regression is v slow)
(alter the kriging error function)

finish requirements.txt


Just to put an upper bound on fit allocation performance:
Instead of doing fitting, try to use the actual local minima that you would reach


Try a different form of variance:
do typical variance, squared distance from mean
in that case, also use value as the smallest point reached so far

figure out what functions this algorithm would work well on,
and which this algorithm would work worse on

look up newtons method, inverse hessian

try more functions, hopefully it works with other functions

apply STAR-SPSA to the things in efficient multi start strategies,
see if performance is better
(could write about this)

Try adding noise to function (add random.random() * something)